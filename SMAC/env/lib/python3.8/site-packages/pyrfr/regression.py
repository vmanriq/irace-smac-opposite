# This file was automatically generated by SWIG (http://www.swig.org).
# Version 4.0.2
#
# Do not make changes to this file unless you know what you are doing--modify
# the SWIG interface file instead.

from sys import version_info as _swig_python_version_info
if _swig_python_version_info < (2, 7, 0):
    raise RuntimeError("Python 2.7 or later required")

# Import the low-level C/C++ module
if __package__ or "." in __name__:
    from . import _regression
else:
    import _regression

try:
    import builtins as __builtin__
except ImportError:
    import __builtin__

def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except __builtin__.Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)


def _swig_setattr_nondynamic_instance_variable(set):
    def set_instance_attr(self, name, value):
        if name == "thisown":
            self.this.own(value)
        elif name == "this":
            set(self, name, value)
        elif hasattr(self, name) and isinstance(getattr(type(self), name), property):
            set(self, name, value)
        else:
            raise AttributeError("You cannot add instance attributes to %s" % self)
    return set_instance_attr


def _swig_setattr_nondynamic_class_variable(set):
    def set_class_attr(cls, name, value):
        if hasattr(cls, name) and not isinstance(getattr(cls, name), property):
            set(cls, name, value)
        else:
            raise AttributeError("You cannot add class attributes to %s" % cls)
    return set_class_attr


def _swig_add_metaclass(metaclass):
    """Class decorator for adding a metaclass to a SWIG wrapped class - a slimmed down version of six.add_metaclass"""
    def wrapper(cls):
        return metaclass(cls.__name__, cls.__bases__, cls.__dict__.copy())
    return wrapper


class _SwigNonDynamicMeta(type):
    """Meta class to enforce nondynamic attributes (no new attributes) for a class"""
    __setattr__ = _swig_setattr_nondynamic_class_variable(type.__setattr__)


class default_random_engine(object, metaclass=_SwigNonDynamicMeta):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _regression.default_random_engine_swiginit(self, _regression.new_default_random_engine(*args))

    def seed(self, arg2: "unsigned int") -> "void":
        return _regression.default_random_engine_seed(self, arg2)
    __swig_destroy__ = _regression.delete_default_random_engine

# Register default_random_engine in _regression:
_regression.default_random_engine_swigregister(default_random_engine)

class SwigPyIterator(object, metaclass=_SwigNonDynamicMeta):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _regression.delete_SwigPyIterator

    def value(self) -> "PyObject *":
        return _regression.SwigPyIterator_value(self)

    def incr(self, n: "size_t"=1) -> "swig::SwigPyIterator *":
        return _regression.SwigPyIterator_incr(self, n)

    def decr(self, n: "size_t"=1) -> "swig::SwigPyIterator *":
        return _regression.SwigPyIterator_decr(self, n)

    def distance(self, x: "SwigPyIterator") -> "ptrdiff_t":
        return _regression.SwigPyIterator_distance(self, x)

    def equal(self, x: "SwigPyIterator") -> "bool":
        return _regression.SwigPyIterator_equal(self, x)

    def copy(self) -> "swig::SwigPyIterator *":
        return _regression.SwigPyIterator_copy(self)

    def next(self) -> "PyObject *":
        return _regression.SwigPyIterator_next(self)

    def __next__(self) -> "PyObject *":
        return _regression.SwigPyIterator___next__(self)

    def previous(self) -> "PyObject *":
        return _regression.SwigPyIterator_previous(self)

    def advance(self, n: "ptrdiff_t") -> "swig::SwigPyIterator *":
        return _regression.SwigPyIterator_advance(self, n)

    def __eq__(self, x: "SwigPyIterator") -> "bool":
        return _regression.SwigPyIterator___eq__(self, x)

    def __ne__(self, x: "SwigPyIterator") -> "bool":
        return _regression.SwigPyIterator___ne__(self, x)

    def __iadd__(self, n: "ptrdiff_t") -> "swig::SwigPyIterator &":
        return _regression.SwigPyIterator___iadd__(self, n)

    def __isub__(self, n: "ptrdiff_t") -> "swig::SwigPyIterator &":
        return _regression.SwigPyIterator___isub__(self, n)

    def __add__(self, n: "ptrdiff_t") -> "swig::SwigPyIterator *":
        return _regression.SwigPyIterator___add__(self, n)

    def __sub__(self, *args) -> "ptrdiff_t":
        return _regression.SwigPyIterator___sub__(self, *args)
    def __iter__(self):
        return self

# Register SwigPyIterator in _regression:
_regression.SwigPyIterator_swigregister(SwigPyIterator)

class num_vector(object, metaclass=_SwigNonDynamicMeta):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        return _regression.num_vector_iterator(self)
    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        return _regression.num_vector___nonzero__(self)

    def __bool__(self) -> "bool":
        return _regression.num_vector___bool__(self)

    def __len__(self) -> "std::vector< double >::size_type":
        return _regression.num_vector___len__(self)

    def __getslice__(self, i: "std::vector< double >::difference_type", j: "std::vector< double >::difference_type") -> "std::vector< double,std::allocator< double > > *":
        return _regression.num_vector___getslice__(self, i, j)

    def __setslice__(self, *args) -> "void":
        return _regression.num_vector___setslice__(self, *args)

    def __delslice__(self, i: "std::vector< double >::difference_type", j: "std::vector< double >::difference_type") -> "void":
        return _regression.num_vector___delslice__(self, i, j)

    def __delitem__(self, *args) -> "void":
        return _regression.num_vector___delitem__(self, *args)

    def __getitem__(self, *args) -> "std::vector< double >::value_type const &":
        return _regression.num_vector___getitem__(self, *args)

    def __setitem__(self, *args) -> "void":
        return _regression.num_vector___setitem__(self, *args)

    def pop(self) -> "std::vector< double >::value_type":
        return _regression.num_vector_pop(self)

    def append(self, x: "std::vector< double >::value_type const &") -> "void":
        return _regression.num_vector_append(self, x)

    def empty(self) -> "bool":
        return _regression.num_vector_empty(self)

    def size(self) -> "std::vector< double >::size_type":
        return _regression.num_vector_size(self)

    def swap(self, v: "num_vector") -> "void":
        return _regression.num_vector_swap(self, v)

    def begin(self) -> "std::vector< double >::iterator":
        return _regression.num_vector_begin(self)

    def end(self) -> "std::vector< double >::iterator":
        return _regression.num_vector_end(self)

    def rbegin(self) -> "std::vector< double >::reverse_iterator":
        return _regression.num_vector_rbegin(self)

    def rend(self) -> "std::vector< double >::reverse_iterator":
        return _regression.num_vector_rend(self)

    def clear(self) -> "void":
        return _regression.num_vector_clear(self)

    def get_allocator(self) -> "std::vector< double >::allocator_type":
        return _regression.num_vector_get_allocator(self)

    def pop_back(self) -> "void":
        return _regression.num_vector_pop_back(self)

    def erase(self, *args) -> "std::vector< double >::iterator":
        return _regression.num_vector_erase(self, *args)

    def __init__(self, *args):
        _regression.num_vector_swiginit(self, _regression.new_num_vector(*args))

    def push_back(self, x: "std::vector< double >::value_type const &") -> "void":
        return _regression.num_vector_push_back(self, x)

    def front(self) -> "std::vector< double >::value_type const &":
        return _regression.num_vector_front(self)

    def back(self) -> "std::vector< double >::value_type const &":
        return _regression.num_vector_back(self)

    def assign(self, n: "std::vector< double >::size_type", x: "std::vector< double >::value_type const &") -> "void":
        return _regression.num_vector_assign(self, n, x)

    def resize(self, *args) -> "void":
        return _regression.num_vector_resize(self, *args)

    def insert(self, *args) -> "void":
        return _regression.num_vector_insert(self, *args)

    def reserve(self, n: "std::vector< double >::size_type") -> "void":
        return _regression.num_vector_reserve(self, n)

    def capacity(self) -> "std::vector< double >::size_type":
        return _regression.num_vector_capacity(self)
    __swig_destroy__ = _regression.delete_num_vector

# Register num_vector in _regression:
_regression.num_vector_swigregister(num_vector)

class idx_vector(object, metaclass=_SwigNonDynamicMeta):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        return _regression.idx_vector_iterator(self)
    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        return _regression.idx_vector___nonzero__(self)

    def __bool__(self) -> "bool":
        return _regression.idx_vector___bool__(self)

    def __len__(self) -> "std::vector< unsigned int >::size_type":
        return _regression.idx_vector___len__(self)

    def __getslice__(self, i: "std::vector< unsigned int >::difference_type", j: "std::vector< unsigned int >::difference_type") -> "std::vector< unsigned int,std::allocator< unsigned int > > *":
        return _regression.idx_vector___getslice__(self, i, j)

    def __setslice__(self, *args) -> "void":
        return _regression.idx_vector___setslice__(self, *args)

    def __delslice__(self, i: "std::vector< unsigned int >::difference_type", j: "std::vector< unsigned int >::difference_type") -> "void":
        return _regression.idx_vector___delslice__(self, i, j)

    def __delitem__(self, *args) -> "void":
        return _regression.idx_vector___delitem__(self, *args)

    def __getitem__(self, *args) -> "std::vector< unsigned int >::value_type const &":
        return _regression.idx_vector___getitem__(self, *args)

    def __setitem__(self, *args) -> "void":
        return _regression.idx_vector___setitem__(self, *args)

    def pop(self) -> "std::vector< unsigned int >::value_type":
        return _regression.idx_vector_pop(self)

    def append(self, x: "std::vector< unsigned int >::value_type const &") -> "void":
        return _regression.idx_vector_append(self, x)

    def empty(self) -> "bool":
        return _regression.idx_vector_empty(self)

    def size(self) -> "std::vector< unsigned int >::size_type":
        return _regression.idx_vector_size(self)

    def swap(self, v: "idx_vector") -> "void":
        return _regression.idx_vector_swap(self, v)

    def begin(self) -> "std::vector< unsigned int >::iterator":
        return _regression.idx_vector_begin(self)

    def end(self) -> "std::vector< unsigned int >::iterator":
        return _regression.idx_vector_end(self)

    def rbegin(self) -> "std::vector< unsigned int >::reverse_iterator":
        return _regression.idx_vector_rbegin(self)

    def rend(self) -> "std::vector< unsigned int >::reverse_iterator":
        return _regression.idx_vector_rend(self)

    def clear(self) -> "void":
        return _regression.idx_vector_clear(self)

    def get_allocator(self) -> "std::vector< unsigned int >::allocator_type":
        return _regression.idx_vector_get_allocator(self)

    def pop_back(self) -> "void":
        return _regression.idx_vector_pop_back(self)

    def erase(self, *args) -> "std::vector< unsigned int >::iterator":
        return _regression.idx_vector_erase(self, *args)

    def __init__(self, *args):
        _regression.idx_vector_swiginit(self, _regression.new_idx_vector(*args))

    def push_back(self, x: "std::vector< unsigned int >::value_type const &") -> "void":
        return _regression.idx_vector_push_back(self, x)

    def front(self) -> "std::vector< unsigned int >::value_type const &":
        return _regression.idx_vector_front(self)

    def back(self) -> "std::vector< unsigned int >::value_type const &":
        return _regression.idx_vector_back(self)

    def assign(self, n: "std::vector< unsigned int >::size_type", x: "std::vector< unsigned int >::value_type const &") -> "void":
        return _regression.idx_vector_assign(self, n, x)

    def resize(self, *args) -> "void":
        return _regression.idx_vector_resize(self, *args)

    def insert(self, *args) -> "void":
        return _regression.idx_vector_insert(self, *args)

    def reserve(self, n: "std::vector< unsigned int >::size_type") -> "void":
        return _regression.idx_vector_reserve(self, n)

    def capacity(self) -> "std::vector< unsigned int >::size_type":
        return _regression.idx_vector_capacity(self)
    __swig_destroy__ = _regression.delete_idx_vector

# Register idx_vector in _regression:
_regression.idx_vector_swigregister(idx_vector)

class num_vector_vector(object, metaclass=_SwigNonDynamicMeta):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        return _regression.num_vector_vector_iterator(self)
    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        return _regression.num_vector_vector___nonzero__(self)

    def __bool__(self) -> "bool":
        return _regression.num_vector_vector___bool__(self)

    def __len__(self) -> "std::vector< std::vector< double > >::size_type":
        return _regression.num_vector_vector___len__(self)

    def __getslice__(self, i: "std::vector< std::vector< double > >::difference_type", j: "std::vector< std::vector< double > >::difference_type") -> "std::vector< std::vector< num_t,std::allocator< num_t > >,std::allocator< std::vector< num_t,std::allocator< num_t > > > > *":
        return _regression.num_vector_vector___getslice__(self, i, j)

    def __setslice__(self, *args) -> "void":
        return _regression.num_vector_vector___setslice__(self, *args)

    def __delslice__(self, i: "std::vector< std::vector< double > >::difference_type", j: "std::vector< std::vector< double > >::difference_type") -> "void":
        return _regression.num_vector_vector___delslice__(self, i, j)

    def __delitem__(self, *args) -> "void":
        return _regression.num_vector_vector___delitem__(self, *args)

    def __getitem__(self, *args) -> "std::vector< std::vector< double > >::value_type const &":
        return _regression.num_vector_vector___getitem__(self, *args)

    def __setitem__(self, *args) -> "void":
        return _regression.num_vector_vector___setitem__(self, *args)

    def pop(self) -> "std::vector< std::vector< double > >::value_type":
        return _regression.num_vector_vector_pop(self)

    def append(self, x: "num_vector") -> "void":
        return _regression.num_vector_vector_append(self, x)

    def empty(self) -> "bool":
        return _regression.num_vector_vector_empty(self)

    def size(self) -> "std::vector< std::vector< double > >::size_type":
        return _regression.num_vector_vector_size(self)

    def swap(self, v: "num_vector_vector") -> "void":
        return _regression.num_vector_vector_swap(self, v)

    def begin(self) -> "std::vector< std::vector< double > >::iterator":
        return _regression.num_vector_vector_begin(self)

    def end(self) -> "std::vector< std::vector< double > >::iterator":
        return _regression.num_vector_vector_end(self)

    def rbegin(self) -> "std::vector< std::vector< double > >::reverse_iterator":
        return _regression.num_vector_vector_rbegin(self)

    def rend(self) -> "std::vector< std::vector< double > >::reverse_iterator":
        return _regression.num_vector_vector_rend(self)

    def clear(self) -> "void":
        return _regression.num_vector_vector_clear(self)

    def get_allocator(self) -> "std::vector< std::vector< double > >::allocator_type":
        return _regression.num_vector_vector_get_allocator(self)

    def pop_back(self) -> "void":
        return _regression.num_vector_vector_pop_back(self)

    def erase(self, *args) -> "std::vector< std::vector< double > >::iterator":
        return _regression.num_vector_vector_erase(self, *args)

    def __init__(self, *args):
        _regression.num_vector_vector_swiginit(self, _regression.new_num_vector_vector(*args))

    def push_back(self, x: "num_vector") -> "void":
        return _regression.num_vector_vector_push_back(self, x)

    def front(self) -> "std::vector< std::vector< double > >::value_type const &":
        return _regression.num_vector_vector_front(self)

    def back(self) -> "std::vector< std::vector< double > >::value_type const &":
        return _regression.num_vector_vector_back(self)

    def assign(self, n: "std::vector< std::vector< double > >::size_type", x: "num_vector") -> "void":
        return _regression.num_vector_vector_assign(self, n, x)

    def resize(self, *args) -> "void":
        return _regression.num_vector_vector_resize(self, *args)

    def insert(self, *args) -> "void":
        return _regression.num_vector_vector_insert(self, *args)

    def reserve(self, n: "std::vector< std::vector< double > >::size_type") -> "void":
        return _regression.num_vector_vector_reserve(self, n)

    def capacity(self) -> "std::vector< std::vector< double > >::size_type":
        return _regression.num_vector_vector_capacity(self)
    __swig_destroy__ = _regression.delete_num_vector_vector

# Register num_vector_vector in _regression:
_regression.num_vector_vector_swigregister(num_vector_vector)

class num_vector_vector_vector(object, metaclass=_SwigNonDynamicMeta):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        return _regression.num_vector_vector_vector_iterator(self)
    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        return _regression.num_vector_vector_vector___nonzero__(self)

    def __bool__(self) -> "bool":
        return _regression.num_vector_vector_vector___bool__(self)

    def __len__(self) -> "std::vector< std::vector< std::vector< double > > >::size_type":
        return _regression.num_vector_vector_vector___len__(self)

    def __getslice__(self, i: "std::vector< std::vector< std::vector< double > > >::difference_type", j: "std::vector< std::vector< std::vector< double > > >::difference_type") -> "std::vector< std::vector< std::vector< num_t,std::allocator< num_t > >,std::allocator< std::vector< num_t,std::allocator< num_t > > > >,std::allocator< std::vector< std::vector< num_t,std::allocator< num_t > >,std::allocator< std::vector< num_t,std::allocator< num_t > > > > > > *":
        return _regression.num_vector_vector_vector___getslice__(self, i, j)

    def __setslice__(self, *args) -> "void":
        return _regression.num_vector_vector_vector___setslice__(self, *args)

    def __delslice__(self, i: "std::vector< std::vector< std::vector< double > > >::difference_type", j: "std::vector< std::vector< std::vector< double > > >::difference_type") -> "void":
        return _regression.num_vector_vector_vector___delslice__(self, i, j)

    def __delitem__(self, *args) -> "void":
        return _regression.num_vector_vector_vector___delitem__(self, *args)

    def __getitem__(self, *args) -> "std::vector< std::vector< std::vector< double > > >::value_type const &":
        return _regression.num_vector_vector_vector___getitem__(self, *args)

    def __setitem__(self, *args) -> "void":
        return _regression.num_vector_vector_vector___setitem__(self, *args)

    def pop(self) -> "std::vector< std::vector< std::vector< double > > >::value_type":
        return _regression.num_vector_vector_vector_pop(self)

    def append(self, x: "num_vector_vector") -> "void":
        return _regression.num_vector_vector_vector_append(self, x)

    def empty(self) -> "bool":
        return _regression.num_vector_vector_vector_empty(self)

    def size(self) -> "std::vector< std::vector< std::vector< double > > >::size_type":
        return _regression.num_vector_vector_vector_size(self)

    def swap(self, v: "num_vector_vector_vector") -> "void":
        return _regression.num_vector_vector_vector_swap(self, v)

    def begin(self) -> "std::vector< std::vector< std::vector< double > > >::iterator":
        return _regression.num_vector_vector_vector_begin(self)

    def end(self) -> "std::vector< std::vector< std::vector< double > > >::iterator":
        return _regression.num_vector_vector_vector_end(self)

    def rbegin(self) -> "std::vector< std::vector< std::vector< double > > >::reverse_iterator":
        return _regression.num_vector_vector_vector_rbegin(self)

    def rend(self) -> "std::vector< std::vector< std::vector< double > > >::reverse_iterator":
        return _regression.num_vector_vector_vector_rend(self)

    def clear(self) -> "void":
        return _regression.num_vector_vector_vector_clear(self)

    def get_allocator(self) -> "std::vector< std::vector< std::vector< double > > >::allocator_type":
        return _regression.num_vector_vector_vector_get_allocator(self)

    def pop_back(self) -> "void":
        return _regression.num_vector_vector_vector_pop_back(self)

    def erase(self, *args) -> "std::vector< std::vector< std::vector< double > > >::iterator":
        return _regression.num_vector_vector_vector_erase(self, *args)

    def __init__(self, *args):
        _regression.num_vector_vector_vector_swiginit(self, _regression.new_num_vector_vector_vector(*args))

    def push_back(self, x: "num_vector_vector") -> "void":
        return _regression.num_vector_vector_vector_push_back(self, x)

    def front(self) -> "std::vector< std::vector< std::vector< double > > >::value_type const &":
        return _regression.num_vector_vector_vector_front(self)

    def back(self) -> "std::vector< std::vector< std::vector< double > > >::value_type const &":
        return _regression.num_vector_vector_vector_back(self)

    def assign(self, n: "std::vector< std::vector< std::vector< double > > >::size_type", x: "num_vector_vector") -> "void":
        return _regression.num_vector_vector_vector_assign(self, n, x)

    def resize(self, *args) -> "void":
        return _regression.num_vector_vector_vector_resize(self, *args)

    def insert(self, *args) -> "void":
        return _regression.num_vector_vector_vector_insert(self, *args)

    def reserve(self, n: "std::vector< std::vector< std::vector< double > > >::size_type") -> "void":
        return _regression.num_vector_vector_vector_reserve(self, n)

    def capacity(self) -> "std::vector< std::vector< std::vector< double > > >::size_type":
        return _regression.num_vector_vector_vector_capacity(self)
    __swig_destroy__ = _regression.delete_num_vector_vector_vector

# Register num_vector_vector_vector in _regression:
_regression.num_vector_vector_vector_swigregister(num_vector_vector_vector)

class num_num_pair(object, metaclass=_SwigNonDynamicMeta):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _regression.num_num_pair_swiginit(self, _regression.new_num_num_pair(*args))
    first = property(_regression.num_num_pair_first_get, _regression.num_num_pair_first_set)
    second = property(_regression.num_num_pair_second_get, _regression.num_num_pair_second_set)
    def __len__(self):
        return 2
    def __repr__(self):
        return str((self.first, self.second))
    def __getitem__(self, index): 
        if not (index % 2):
            return self.first
        else:
            return self.second
    def __setitem__(self, index, val):
        if not (index % 2):
            self.first = val
        else:
            self.second = val
    __swig_destroy__ = _regression.delete_num_num_pair

# Register num_num_pair in _regression:
_regression.num_num_pair_swigregister(num_num_pair)

class data_base(object, metaclass=_SwigNonDynamicMeta):
    r"""


    The interface for any data container with the minimal functionality.  

    C++ includes: data_container.hpp

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _regression.delete_data_base

    def feature(self, feature_index: "unsigned int", sample_index: "unsigned int") -> "double":
        r"""

        `feature(index_t feature_index, index_t sample_index) const =0 -> num_t`  

        Function for accessing a single feature value, consistency checks might be
        omitted for performance.  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_index` :  
            The index of the data point.  

        Returns
        -------
        the stored value  

        """
        return _regression.data_base_feature(self, feature_index, sample_index)

    def features(self, feature_index: "unsigned int", sample_indices: "idx_vector") -> "std::vector< double,std::allocator< double > >":
        r"""

        `features(index_t feature_index, const std::vector< index_t > &sample_indices)
            const =0 -> std::vector< num_t >`  

        member function for accessing the feature values of multiple data points at
        once, consistency checks might be omitted for performance  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_indices` :  
            The indices of the data point.  

        Returns
        -------
        the stored values  

        """
        return _regression.data_base_features(self, feature_index, sample_indices)

    def response(self, sample_index: "unsigned int") -> "double":
        r"""

        `response(index_t sample_index) const =0 -> response_t`  

        member function to query a single response value, consistency checks might be
        omitted for performance  

        Parameters
        ----------
        * `sample_index` :  
            the response of which data point  

        Returns
        -------
        the response value  

        """
        return _regression.data_base_response(self, sample_index)

    def predict_value(self, sample_index: "unsigned int") -> "double":
        r"""

        `predict_value(index_t sample_index) const =0 -> response_t`  

        member function to query a single response value, consistency checks might be
        omitted for performance  

        Parameters
        ----------
        * `sample_index` :  
            the response of which data point  

        Returns
        -------
        the prediction value  

        """
        return _regression.data_base_predict_value(self, sample_index)

    def weight(self, sample_index: "unsigned int") -> "double":
        r"""

        `weight(index_t sample_index) const =0 -> num_t`  

        function to access the weight attributed to a single data point  

        Parameters
        ----------
        * `sample_index` :  
            which data point  

        Returns
        -------
        the weigth of that sample  

        """
        return _regression.data_base_weight(self, sample_index)

    def add_data_point(self, *args) -> "void":
        r"""

        `add_data_point(std::vector< num_t > features, std::vector< response_t >
            response, num_t weight)=0`  

        method to add a single data point  

        Parameters
        ----------
        * `features` :  
            a vector containing the features  
        * `response` :  
            the corresponding response vector. The first entry is the value used to fit
            the trees with, the second is used to predict.  
        * `weight` :  
            the weight of the data point  

        """
        return _regression.data_base_add_data_point(self, *args)

    def retrieve_data_point(self, index: "unsigned int") -> "std::vector< double,std::allocator< double > >":
        r"""

        `retrieve_data_point(index_t index) const =0 -> std::vector< num_t >`  

        method to retrieve a data point  

        Parameters
        ----------
        * `index` :  
            index of the datapoint to extract  

        Returns
        -------
        std::vector<num_t> the features of the data point  

        """
        return _regression.data_base_retrieve_data_point(self, index)

    def get_type_of_feature(self, feature_index: "unsigned int") -> "unsigned int":
        r"""

        `get_type_of_feature(index_t feature_index) const =0 -> index_t`  

        query the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        int type of the feature: 0 - numerical value (float or int); n>0 - categorical
        value with n different values {0,1,...,n-1}  

        """
        return _regression.data_base_get_type_of_feature(self, feature_index)

    def get_type_of_response(self) -> "unsigned int":
        r"""

        `get_type_of_response() const =0 -> index_t`  

        query the type of the response  

        Returns
        -------
        index_t type of the response: 0 - numerical value (float or int); n>0 -
        categorical value with n different values {0,1,...,n-1}  

        """
        return _regression.data_base_get_type_of_response(self)

    def set_type_of_feature(self, feature_index: "unsigned int", feature_type: "unsigned int") -> "void":
        r"""

        `set_type_of_feature(index_t feature_index, index_t feature_type)=0`  

        specifying the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature whose type is specified  
        * `feature_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.data_base_set_type_of_feature(self, feature_index, feature_type)

    def set_type_of_response(self, response_type: "unsigned int") -> "void":
        r"""

        `set_type_of_response(index_t response_type)=0`  

        specifying the type of the response  

        Parameters
        ----------
        * `response_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.data_base_set_type_of_response(self, response_type)

    def set_bounds_of_feature(self, feature_index: "unsigned int", min: "double", max: "double") -> "void":
        r"""

        `set_bounds_of_feature(index_t feature_index, num_t min, num_t max)=0`  

        specifies the interval of allowed values for a feature  

        To marginalize out certain feature dimensions using non-i.i.d. data, the
        numerical bounds on each variable have to be known. This only applies to
        numerical features.  

        Note: The forest will not check if a datapoint is consistent with the specified
        bounds!  

        Parameters
        ----------
        * `feature_index` :  
            feature_index the index of the feature  
        * `min` :  
            the smallest value for the feature  
        * `max` :  
            the largest value for the feature  

        """
        return _regression.data_base_set_bounds_of_feature(self, feature_index, min, max)

    def get_bounds_of_feature(self, feature_index: "unsigned int") -> "std::pair< double,double >":
        r"""

        `get_bounds_of_feature(index_t feature_index) const =0 -> std::pair< num_t,
            num_t >`  

        query the allowed interval for a feature; applies only to continuous variables  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        std::pair<num_t,num_t> interval of allowed values  

        """
        return _regression.data_base_get_bounds_of_feature(self, feature_index)

    def num_features(self) -> "unsigned int":
        r"""

        `num_features() const =0 -> index_t`  

        the number of features of every datapoint in the container  

        """
        return _regression.data_base_num_features(self)

    def num_data_points(self) -> "unsigned int":
        r"""

        `num_data_points() const =0 -> index_t`  

        the number of data points in the container  

        """
        return _regression.data_base_num_data_points(self)

# Register data_base in _regression:
_regression.data_base_swigregister(data_base)

class default_data_container(data_base):
    r"""


    A data container for mostly continuous data.  

    It might happen that only a small fraction of all features is categorical. In
    that case it would be wasteful to store the type of every feature separately.
    Instead, this data_container only stores the non-continuous ones in a hash-map.  

    C++ includes: default_data_container.hpp

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, num_f: "unsigned int"):
        r"""

        `default_container(index_t num_f)`  

        """
        _regression.default_data_container_swiginit(self, _regression.new_default_data_container(num_f))

    def init_protected(self, num_f: "unsigned int") -> "void":
        r"""

        `init_protected(index_t num_f)`  

        """
        return _regression.default_data_container_init_protected(self, num_f)

    def feature(self, feature_index: "unsigned int", sample_index: "unsigned int") -> "double":
        r"""

        `feature(index_t feature_index, index_t sample_index) const  -> num_t`  

        Function for accessing a single feature value, consistency checks might be
        omitted for performance.  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_index` :  
            The index of the data point.  

        Returns
        -------
        the stored value  

        """
        return _regression.default_data_container_feature(self, feature_index, sample_index)

    def features(self, feature_index: "unsigned int", sample_indices: "idx_vector") -> "std::vector< double,std::allocator< double > >":
        r"""

        `features(index_t feature_index, const std::vector< index_t > &sample_indices)
            const  -> std::vector< num_t >`  

        member function for accessing the feature values of multiple data points at
        once, consistency checks might be omitted for performance  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_indices` :  
            The indices of the data point.  

        Returns
        -------
        the stored values  

        """
        return _regression.default_data_container_features(self, feature_index, sample_indices)

    def response(self, sample_index: "unsigned int") -> "double":
        r"""

        `response(index_t sample_index) const  -> response_t`  

        member function to query a single response value, consistency checks might be
        omitted for performance  

        Parameters
        ----------
        * `sample_index` :  
            the response of which data point  

        Returns
        -------
        the response value  

        """
        return _regression.default_data_container_response(self, sample_index)

    def predict_value(self, sample_index: "unsigned int") -> "double":
        r"""

        `predict_value(index_t sample_index) const  -> response_t`  

        member function to query a single response value, consistency checks might be
        omitted for performance  

        Parameters
        ----------
        * `sample_index` :  
            the response of which data point  

        Returns
        -------
        the prediction value  

        """
        return _regression.default_data_container_predict_value(self, sample_index)

    def add_data_point(self, *args) -> "void":
        r"""

        `add_data_point(std::vector< num_t > features, std::vector< response_t >
            response, num_t weight=1)`  

        method to add a single data point  

        Parameters
        ----------
        * `features` :  
            a vector containing the features  
        * `response` :  
            the corresponding response vector. The first entry is the value used to fit
            the trees with, the second is used to predict.  
        * `weight` :  
            the weight of the data point  

        """
        return _regression.default_data_container_add_data_point(self, *args)

    def retrieve_data_point(self, index: "unsigned int") -> "std::vector< double,std::allocator< double > >":
        r"""

        `retrieve_data_point(index_t index) const  -> std::vector< num_t >`  

        method to retrieve a data point  

        Parameters
        ----------
        * `index` :  
            index of the datapoint to extract  

        Returns
        -------
        std::vector<num_t> the features of the data point  

        """
        return _regression.default_data_container_retrieve_data_point(self, index)

    def weight(self, sample_index: "unsigned int") -> "double":
        r"""

        `weight(index_t sample_index) const  -> num_t`  

        function to access the weight attributed to a single data point  

        Parameters
        ----------
        * `sample_index` :  
            which data point  

        Returns
        -------
        the weigth of that sample  

        """
        return _regression.default_data_container_weight(self, sample_index)

    def get_type_of_feature(self, feature_index: "unsigned int") -> "unsigned int":
        r"""

        `get_type_of_feature(index_t feature_index) const  -> index_t`  

        query the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        int type of the feature: 0 - numerical value (float or int); n>0 - categorical
        value with n different values {0,1,...,n-1}  

        As most features are assumed to be numerical, it is actually beneficial to store
        only the categorical exceptions in a hash-map. Type = 0 means continuous, and
        Type = n >= 1 means categorical with options in {0, n-1}.  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        int type of the feature: 0 - numerical value (float or int); n>0 - categorical
        value with n different values {1,2,...,n}  

        """
        return _regression.default_data_container_get_type_of_feature(self, feature_index)

    def set_type_of_feature(self, index: "unsigned int", type: "unsigned int") -> "void":
        r"""

        `set_type_of_feature(index_t index, index_t type)`  

        specifying the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature whose type is specified  
        * `feature_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.default_data_container_set_type_of_feature(self, index, type)

    def num_features(self) -> "unsigned int":
        r"""

        `num_features() const  -> index_t`  

        the number of features of every datapoint in the container  

        """
        return _regression.default_data_container_num_features(self)

    def num_data_points(self) -> "unsigned int":
        r"""

        `num_data_points() const  -> index_t`  

        the number of data points in the container  

        """
        return _regression.default_data_container_num_data_points(self)

    def get_type_of_response(self) -> "unsigned int":
        r"""

        `get_type_of_response() const  -> index_t`  

        query the type of the response  

        Returns
        -------
        index_t type of the response: 0 - numerical value (float or int); n>0 -
        categorical value with n different values {0,1,...,n-1}  

        """
        return _regression.default_data_container_get_type_of_response(self)

    def set_type_of_response(self, resp_t: "unsigned int") -> "void":
        r"""

        `set_type_of_response(index_t resp_t)`  

        specifying the type of the response  

        Parameters
        ----------
        * `response_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.default_data_container_set_type_of_response(self, resp_t)

    def set_bounds_of_feature(self, feature_index: "unsigned int", min: "double", max: "double") -> "void":
        r"""

        `set_bounds_of_feature(index_t feature_index, num_t min, num_t max)`  

        specifies the interval of allowed values for a feature  

        To marginalize out certain feature dimensions using non-i.i.d. data, the
        numerical bounds on each variable have to be known. This only applies to
        numerical features.  

        Note: The forest will not check if a datapoint is consistent with the specified
        bounds!  

        Parameters
        ----------
        * `feature_index` :  
            feature_index the index of the feature  
        * `min` :  
            the smallest value for the feature  
        * `max` :  
            the largest value for the feature  

        """
        return _regression.default_data_container_set_bounds_of_feature(self, feature_index, min, max)

    def get_bounds_of_feature(self, feature_index: "unsigned int") -> "std::pair< double,double >":
        r"""

        `get_bounds_of_feature(index_t feature_index) const  -> std::pair< num_t, num_t
            >`  

        query the allowed interval for a feature; applies only to continuous variables  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        std::pair<num_t,num_t> interval of allowed values  

        """
        return _regression.default_data_container_get_bounds_of_feature(self, feature_index)

    def get_min_max_of_feature(self, feature_index: "unsigned int") -> "std::pair< double,double >":
        r"""

        `get_min_max_of_feature(index_t feature_index) const  -> std::pair< num_t, num_t
            >`  

        """
        return _regression.default_data_container_get_min_max_of_feature(self, feature_index)

    def guess_bounds_from_data(self) -> "void":
        r"""

        `guess_bounds_from_data()`  

        """
        return _regression.default_data_container_guess_bounds_from_data(self)

    def normalize_data(self) -> "void":
        r"""

        `normalize_data()`  

        """
        return _regression.default_data_container_normalize_data(self)

    def import_csv_files(self, *args) -> "int":
        r"""

        `import_csv_files(const std::string &feature_file, const std::string
            &response_file, std::string weight_file="") -> int`  

        """
        return _regression.default_data_container_import_csv_files(self, *args)

    def check_consistency(self) -> "bool":
        r"""

        `check_consistency() -> bool`  

        """
        return _regression.default_data_container_check_consistency(self)

    def print_data(self) -> "void":
        r"""

        `print_data()`  

        """
        return _regression.default_data_container_print_data(self)
    __swig_destroy__ = _regression.delete_default_data_container

# Register default_data_container in _regression:
_regression.default_data_container_swigregister(default_data_container)

class default_data_container_with_instances(data_base):
    r"""


    A data container for mostly continuous data with instances.  

    Similar to the mostly_continuous_data container, but with the capability to
    handle instance features.  

    C++ includes: default_data_container_with_instances.hpp

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, *args):
        r"""

        `default_container_with_instances(index_t num_config_f, index_t num_instance_f)`  

        """
        _regression.default_data_container_with_instances_swiginit(self, _regression.new_default_data_container_with_instances(*args))

    def feature(self, feature_index: "unsigned int", sample_index: "unsigned int") -> "double":
        r"""

        `feature(index_t feature_index, index_t sample_index) const  -> num_t`  

        Function for accessing a single feature value, consistency checks might be
        omitted for performance.  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_index` :  
            The index of the data point.  

        Returns
        -------
        the stored value  

        """
        return _regression.default_data_container_with_instances_feature(self, feature_index, sample_index)

    def features(self, feature_index: "unsigned int", sample_indices: "idx_vector") -> "std::vector< double,std::allocator< double > >":
        r"""

        `features(index_t feature_index, const std::vector< index_t > &sample_indices)
            const  -> std::vector< num_t >`  

        member function for accessing the feature values of multiple data points at
        once, consistency checks might be omitted for performance  

        Parameters
        ----------
        * `feature_index` :  
            The index of the feature requested  
        * `sample_indices` :  
            The indices of the data point.  

        Returns
        -------
        the stored values  

        """
        return _regression.default_data_container_with_instances_features(self, feature_index, sample_indices)

    def response(self, sample_index: "unsigned int") -> "double":
        r"""

        `response(index_t sample_index) const  -> response_t`  

        member function to query a single response value, consistency checks might be
        omitted for performance  

        Parameters
        ----------
        * `sample_index` :  
            the response of which data point  

        Returns
        -------
        the response value  

        """
        return _regression.default_data_container_with_instances_response(self, sample_index)

    def predict_value(self, sample_index: "unsigned int") -> "double":
        r"""

        `predict_value(index_t sample_index) const  -> response_t`  

        member function to query a single response value, consistency checks might be
        omitted for performance  

        Parameters
        ----------
        * `sample_index` :  
            the response of which data point  

        Returns
        -------
        the prediction value  

        """
        return _regression.default_data_container_with_instances_predict_value(self, sample_index)

    def add_data_point(self, *args) -> "void":
        r"""

        `add_data_point(index_t config_index, index_t instance_index, response_t r,
            num_t weight=1)`  

        """
        return _regression.default_data_container_with_instances_add_data_point(self, *args)

    def weight(self, sample_index: "unsigned int") -> "double":
        r"""

        `weight(index_t sample_index) const  -> num_t`  

        function to access the weight attributed to a single data point  

        Parameters
        ----------
        * `sample_index` :  
            which data point  

        Returns
        -------
        the weigth of that sample  

        """
        return _regression.default_data_container_with_instances_weight(self, sample_index)

    def num_configurations(self) -> "unsigned int":
        r"""

        `num_configurations() -> index_t`  

        """
        return _regression.default_data_container_with_instances_num_configurations(self)

    def num_instances(self) -> "unsigned int":
        r"""

        `num_instances() -> index_t`  

        """
        return _regression.default_data_container_with_instances_num_instances(self)

    def add_configuration(self, config_features: "num_vector") -> "unsigned int":
        r"""

        `add_configuration(const std::vector< num_t > &config_features) -> index_t`  

        """
        return _regression.default_data_container_with_instances_add_configuration(self, config_features)

    def add_instance(self, instance_features: "num_vector") -> "unsigned int":
        r"""

        `add_instance(const std::vector< num_t > instance_features) -> index_t`  

        """
        return _regression.default_data_container_with_instances_add_instance(self, instance_features)

    def retrieve_data_point(self, index: "unsigned int") -> "std::vector< double,std::allocator< double > >":
        r"""

        `retrieve_data_point(index_t index) const  -> std::vector< num_t >`  

        method to retrieve a data point  

        Parameters
        ----------
        * `index` :  
            index of the datapoint to extract  

        Returns
        -------
        std::vector<num_t> the features of the data point  

        """
        return _regression.default_data_container_with_instances_retrieve_data_point(self, index)

    def get_type_of_feature(self, feature_index: "unsigned int") -> "unsigned int":
        r"""

        `get_type_of_feature(index_t feature_index) const  -> index_t`  

        query the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        int type of the feature: 0 - numerical value (float or int); n>0 - categorical
        value with n different values {0,1,...,n-1}  

        """
        return _regression.default_data_container_with_instances_get_type_of_feature(self, feature_index)

    def set_type_of_configuration_feature(self, index: "unsigned int", type: "unsigned int") -> "void":
        r"""

        `set_type_of_configuration_feature(index_t index, index_t type)`  

        """
        return _regression.default_data_container_with_instances_set_type_of_configuration_feature(self, index, type)

    def set_type_of_instance_feature(self, index: "unsigned int", type: "unsigned int") -> "void":
        r"""

        `set_type_of_instance_feature(index_t index, index_t type)`  

        """
        return _regression.default_data_container_with_instances_set_type_of_instance_feature(self, index, type)

    def set_type_of_feature(self, index: "unsigned int", type: "unsigned int") -> "void":
        r"""

        `set_type_of_feature(index_t index, index_t type)`  

        specifying the type of a feature  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature whose type is specified  
        * `feature_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.default_data_container_with_instances_set_type_of_feature(self, index, type)

    def num_features(self) -> "unsigned int":
        r"""

        `num_features() const  -> index_t`  

        the number of features of every datapoint in the container  

        """
        return _regression.default_data_container_with_instances_num_features(self)

    def num_data_points(self) -> "unsigned int":
        r"""

        `num_data_points() const  -> index_t`  

        the number of data points in the container  

        """
        return _regression.default_data_container_with_instances_num_data_points(self)

    def check_consistency(self) -> "void":
        r"""

        `check_consistency()`  

        """
        return _regression.default_data_container_with_instances_check_consistency(self)

    def get_type_of_response(self) -> "unsigned int":
        r"""

        `get_type_of_response() const  -> index_t`  

        query the type of the response  

        Returns
        -------
        index_t type of the response: 0 - numerical value (float or int); n>0 -
        categorical value with n different values {0,1,...,n-1}  

        """
        return _regression.default_data_container_with_instances_get_type_of_response(self)

    def set_type_of_response(self, resp_t: "unsigned int") -> "void":
        r"""

        `set_type_of_response(index_t resp_t)`  

        specifying the type of the response  

        Parameters
        ----------
        * `response_type` :  
            the actual type (0 - numerical, value >0 catergorical with values from
            {0,1,...value-1}  

        """
        return _regression.default_data_container_with_instances_set_type_of_response(self, resp_t)

    def set_bounds_of_feature(self, feature_index: "unsigned int", min: "double", max: "double") -> "void":
        r"""

        `set_bounds_of_feature(index_t feature_index, num_t min, num_t max)`  

        specifies the interval of allowed values for a feature  

        To marginalize out certain feature dimensions using non-i.i.d. data, the
        numerical bounds on each variable have to be known. This only applies to
        numerical features.  

        Note: The forest will not check if a datapoint is consistent with the specified
        bounds!  

        Parameters
        ----------
        * `feature_index` :  
            feature_index the index of the feature  
        * `min` :  
            the smallest value for the feature  
        * `max` :  
            the largest value for the feature  

        """
        return _regression.default_data_container_with_instances_set_bounds_of_feature(self, feature_index, min, max)

    def get_bounds_of_feature(self, feature_index: "unsigned int") -> "std::pair< double,double >":
        r"""

        `get_bounds_of_feature(index_t feature_index) const  -> std::pair< num_t, num_t
            >`  

        query the allowed interval for a feature; applies only to continuous variables  

        Parameters
        ----------
        * `feature_index` :  
            the index of the feature  

        Returns
        -------
        std::pair<num_t,num_t> interval of allowed values  

        """
        return _regression.default_data_container_with_instances_get_bounds_of_feature(self, feature_index)

    def get_instance_set(self) -> "std::vector< double,std::allocator< double > >":
        r"""

        `get_instance_set() -> std::vector< num_t >`  

        method to get instance as set_feature for
        predict_mean_var_of_mean_response_on_set method in regression forest  

        """
        return _regression.default_data_container_with_instances_get_instance_set(self)

    def get_configuration_set(self, configuration_index: "double") -> "std::vector< double,std::allocator< double > >":
        r"""

        `get_configuration_set(num_t configuration_index) -> std::vector< num_t >`  

        """
        return _regression.default_data_container_with_instances_get_configuration_set(self, configuration_index)

    def get_features_by_configuration_and_instance(self, configuration_index: "double", instance_index: "double") -> "std::vector< double,std::allocator< double > >":
        r"""

        `get_features_by_configuration_and_instance(num_t configuration_index, num_t
            instance_index) -> std::vector< num_t >`  

        """
        return _regression.default_data_container_with_instances_get_features_by_configuration_and_instance(self, configuration_index, instance_index)
    __swig_destroy__ = _regression.delete_default_data_container_with_instances

# Register default_data_container_with_instances in _regression:
_regression.default_data_container_with_instances_swigregister(default_data_container_with_instances)

class tree_opts(object, metaclass=_SwigNonDynamicMeta):
    r"""


    Attributes
    ----------
    * `max_features` : `index_t`  
        number of features to consider for each split  

    * `max_depth` : `index_t`  
        maximum depth for the tree  

    * `min_samples_to_split` : `index_t`  
        minumum number of samples to try splitting  

    * `min_weight_to_split` : `num_t`  
        minumum weight of samples to try splitting  

    * `min_samples_in_leaf` : `index_t`  
        minimum total sample weights in a leaf  

    * `min_weight_in_leaf` : `num_t`  
        minimum total sample weights in a leaf  

    * `max_num_nodes` : `index_t`  
        maxmimum total number of nodes in the tree  

    * `max_num_leaves` : `index_t`  
        maxmimum total number of leaves in the tree  

    * `epsilon_purity` : `response_t`  
        minimum difference between two response values to be considered different*/  

    * `life_time` : `num_t`  
        life time of a mondrian tree  

    * `hierarchical_smoothing` : `bool`  
        flag to enable/disable hierachical smoothing for mondrian forests  

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr
    max_features = property(_regression.tree_opts_max_features_get, _regression.tree_opts_max_features_set)
    max_depth = property(_regression.tree_opts_max_depth_get, _regression.tree_opts_max_depth_set)
    min_samples_to_split = property(_regression.tree_opts_min_samples_to_split_get, _regression.tree_opts_min_samples_to_split_set)
    min_weight_to_split = property(_regression.tree_opts_min_weight_to_split_get, _regression.tree_opts_min_weight_to_split_set)
    min_samples_in_leaf = property(_regression.tree_opts_min_samples_in_leaf_get, _regression.tree_opts_min_samples_in_leaf_set)
    min_weight_in_leaf = property(_regression.tree_opts_min_weight_in_leaf_get, _regression.tree_opts_min_weight_in_leaf_set)
    max_num_nodes = property(_regression.tree_opts_max_num_nodes_get, _regression.tree_opts_max_num_nodes_set)
    max_num_leaves = property(_regression.tree_opts_max_num_leaves_get, _regression.tree_opts_max_num_leaves_set)
    epsilon_purity = property(_regression.tree_opts_epsilon_purity_get, _regression.tree_opts_epsilon_purity_set)
    life_time = property(_regression.tree_opts_life_time_get, _regression.tree_opts_life_time_set)
    hierarchical_smoothing = property(_regression.tree_opts_hierarchical_smoothing_get, _regression.tree_opts_hierarchical_smoothing_set)

    def set_default_values(self) -> "void":
        r"""

        `set_default_values()`  

        (Re)set to default values with no limits on the size of the tree  

        If nothing is know about the data, this member can be used to get a valid
        setting for the tree_options struct. But beware this setting could lead to a
        huge tree depending on the amount of data. There is no limit to the size, and
        nodes are split into pure leafs. For each split, every feature is considered!
        This not only slows the training down, but also makes this tree deterministic!  

        """
        return _regression.tree_opts_set_default_values(self)

    def __init__(self, *args):
        r"""

        `tree_options(rfr::data_containers::base< num_t, response_t, index_t > &data)`  

        Constructor that adjusts the number of features considered at each split
        proportional to the square root of the number of features.  

        """
        _regression.tree_opts_swiginit(self, _regression.new_tree_opts(*args))

    def adjust_limits_to_data(self, data: "data_base") -> "void":
        r"""

        `adjust_limits_to_data(const rfr::data_containers::base< num_t, response_t,
            index_t > &data)`  

        """
        return _regression.tree_opts_adjust_limits_to_data(self, data)

    def print_info(self) -> "void":
        r"""

        `print_info()`  

        """
        return _regression.tree_opts_print_info(self)
    __swig_destroy__ = _regression.delete_tree_opts

# Register tree_opts in _regression:
_regression.tree_opts_swigregister(tree_opts)

class base_tree(object, metaclass=_SwigNonDynamicMeta):
    r"""


    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _regression.delete_base_tree

    def fit(self, *args) -> "void":
        r"""

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data,
            rfr::trees::tree_options< num_t, response_t, index_t > tree_opts, const
            std::vector< num_t > &sample_weights, rng_type &rng)=0`  

        fits a (possibly randomized) decision tree to a subset of the data  

        At each node, if it is 'splitworthy', a random subset of all features is
        considered for the split. Depending on the split_type provided, greedy or
        randomized choices can be made. Just make sure the max_features in tree_opts to
        a number smaller than the number of features!  

        Parameters
        ----------
        * `data` :  
            the container holding the training data  
        * `tree_opts` :  
            a tree_options opject that controls certain aspects of "growing" the tree  
        * `sample_weights` :  
            vector containing the weights of all datapoints, can be used for subsampling
            (no checks are done here!)  
        * `rng` :  
            a (pseudo) random number generator  

        """
        return _regression.base_tree_fit(self, *args)

    def predict(self, feature_vector: "num_vector") -> "double":
        r"""

        `predict(const std::vector< num_t > &feature_vector) const =0 -> response_t`  

        predicts the response value for a single feature vector  

        Parameters
        ----------
        * `feature_vector` :  
            an array containing a valid (in terms of size and values!) feature vector  

        Returns
        -------
        num_t the prediction of the response value (usually the mean of all responses in
        the corresponding leaf)  

        """
        return _regression.base_tree_predict(self, feature_vector)

    def leaf_entries(self, feature_vector: "num_vector") -> "std::vector< double,std::allocator< double > > const &":
        r"""

        `leaf_entries(const std::vector< num_t > &feature_vector) const =0 ->
            std::vector< response_t > const &`  

        returns all response values in the leaf into which the given feature vector
        falls  

        Parameters
        ----------
        * `feature_vector` :  
            an array containing a valid (in terms of size and values!) feature vector  

        Returns
        -------
        std::vector<response_t> all response values in that leaf  

        """
        return _regression.base_tree_leaf_entries(self, feature_vector)

    def number_of_nodes(self) -> "unsigned int":
        r"""

        `number_of_nodes() const =0 -> index_t`  

        """
        return _regression.base_tree_number_of_nodes(self)

    def number_of_leafs(self) -> "unsigned int":
        r"""

        `number_of_leafs() const =0 -> index_t`  

        """
        return _regression.base_tree_number_of_leafs(self)

    def depth(self) -> "unsigned int":
        r"""

        `depth() const =0 -> index_t`  

        """
        return _regression.base_tree_depth(self)

    def save_latex_representation(self, filename: "char const *") -> "void":
        r"""

        `save_latex_representation(const char *filename) const =0`  

        creates a LaTeX document visualizing the tree  

        """
        return _regression.base_tree_save_latex_representation(self, filename)

# Register base_tree in _regression:
_regression.base_tree_swigregister(base_tree)

class binary_full_tree_rss(base_tree):
    r"""


    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def __init__(self):
        r"""

        `k_ary_random_tree()`  

        """
        _regression.binary_full_tree_rss_swiginit(self, _regression.new_binary_full_tree_rss())
    __swig_destroy__ = _regression.delete_binary_full_tree_rss

    def fit(self, data: "data_base", tree_opts: "tree_opts", sample_weights: "num_vector", rng: "default_random_engine") -> "void":
        r"""

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data,
            rfr::trees::tree_options< num_t, response_t, index_t > tree_opts, const
            std::vector< num_t > &sample_weights, rng_type &rng)`  

        fits a randomized decision tree to a subset of the data  

        At each node, if it is 'splitworthy', a random subset of all features is
        considered for the split. Depending on the split_type provided, greedy or
        randomized choices can be made. Just make sure the max_features in tree_opts to
        a number smaller than the number of features!  

        Parameters
        ----------
        * `data` :  
            the container holding the training data  
        * `tree_opts` :  
            a tree_options object that controls certain aspects of "growing" the tree  
        * `sample_weights` :  
            vector containing the weights of all allowed datapoints (set to individual
            entries to zero for subsampling), no checks are done here!  
        * `rng` :  
            the random number generator to be used  

        """
        return _regression.binary_full_tree_rss_fit(self, data, tree_opts, sample_weights, rng)

    def find_leaf_index(self, feature_vector: "num_vector") -> "unsigned int":
        r"""

        `find_leaf_index(const std::vector< num_t > &feature_vector) const  -> index_t`  

        """
        return _regression.binary_full_tree_rss_find_leaf_index(self, feature_vector)

    def get_leaf(self, feature_vector: "num_vector") -> "rfr::nodes::k_ary_node_full< 2,rfr::splits::binary_split_one_feature_rss_loss< double,double,unsigned int,std::default_random_engine,128 >,double,double,unsigned int,std::default_random_engine > const &":
        r"""

        `get_leaf(const std::vector< num_t > &feature_vector) const  -> const node_type
            &`  

        """
        return _regression.binary_full_tree_rss_get_leaf(self, feature_vector)

    def leaf_entries(self, feature_vector: "num_vector") -> "std::vector< double,std::allocator< double > > const &":
        r"""

        `leaf_entries(const std::vector< num_t > &feature_vector) const  -> std::vector<
            response_t > const &`  

        returns all response values in the leaf into which the given feature vector
        falls  

        Parameters
        ----------
        * `feature_vector` :  
            an array containing a valid (in terms of size and values!) feature vector  

        Returns
        -------
        std::vector<response_t> all response values in that leaf  

        """
        return _regression.binary_full_tree_rss_leaf_entries(self, feature_vector)

    def leaf_statistic(self, feature_vector: "num_vector") -> "rfr::util::weighted_running_statistics< double > const &":
        r"""

        `leaf_statistic(const std::vector< num_t > &feature_vector) const  ->
            rfr::util::weighted_running_statistics< num_t > const &`  

        """
        return _regression.binary_full_tree_rss_leaf_statistic(self, feature_vector)

    def predict(self, feature_vector: "num_vector") -> "double":
        r"""

        `predict(const std::vector< num_t > &feature_vector) const  -> response_t`  

        predicts the response value for a single feature vector  

        Parameters
        ----------
        * `feature_vector` :  
            an array containing a valid (in terms of size and values!) feature vector  

        Returns
        -------
        num_t the prediction of the response value (usually the mean of all responses in
        the corresponding leaf)  

        """
        return _regression.binary_full_tree_rss_predict(self, feature_vector)

    def marginalized_mean_prediction(self, feature_vector: "num_vector", node_index: "unsigned int"=0) -> "double":
        r"""

        `marginalized_mean_prediction(const std::vector< num_t > &feature_vector,
            index_t node_index=0) const  -> num_t`  

        """
        return _regression.binary_full_tree_rss_marginalized_mean_prediction(self, feature_vector, node_index)

    def number_of_nodes(self) -> "unsigned int":
        r"""

        `number_of_nodes() const  -> index_t`  

        """
        return _regression.binary_full_tree_rss_number_of_nodes(self)

    def number_of_leafs(self) -> "unsigned int":
        r"""

        `number_of_leafs() const  -> index_t`  

        """
        return _regression.binary_full_tree_rss_number_of_leafs(self)

    def depth(self) -> "unsigned int":
        r"""

        `depth() const  -> index_t`  

        """
        return _regression.binary_full_tree_rss_depth(self)

    def partition_recursor(self, the_partition: "num_vector_vector_vector", subspace: "num_vector_vector", node_index: "double") -> "void":
        r"""

        `partition_recursor(std::vector< std::vector< std::vector< num_t > > >
            &the_partition, std::vector< std::vector< num_t > > &subspace, num_t
            node_index) const `  

        """
        return _regression.binary_full_tree_rss_partition_recursor(self, the_partition, subspace, node_index)

    def partition(self, pcs: "num_vector_vector") -> "std::vector< std::vector< std::vector< num_t,std::allocator< num_t > >,std::allocator< std::vector< num_t,std::allocator< num_t > > > >,std::allocator< std::vector< std::vector< num_t,std::allocator< num_t > >,std::allocator< std::vector< num_t,std::allocator< num_t > > > > > >":
        r"""

        `partition(std::vector< std::vector< num_t > > pcs) const  -> std::vector<
            std::vector< std::vector< num_t > > >`  

        """
        return _regression.binary_full_tree_rss_partition(self, pcs)

    def total_weight_in_subtree(self, node_index: "unsigned int") -> "double":
        r"""

        `total_weight_in_subtree(index_t node_index) const  -> num_t`  

        """
        return _regression.binary_full_tree_rss_total_weight_in_subtree(self, node_index)

    def check_split_fractions(self, epsilon: "double"=1e-6) -> "bool":
        r"""

        `check_split_fractions(num_t epsilon=1e-6) const  -> bool`  

        """
        return _regression.binary_full_tree_rss_check_split_fractions(self, epsilon)

    def pseudo_update(self, features: "num_vector", response: "double", weight: "double") -> "void":
        r"""

        `pseudo_update(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.binary_full_tree_rss_pseudo_update(self, features, response, weight)

    def pseudo_downdate(self, features: "num_vector", response: "double", weight: "double") -> "void":
        r"""

        `pseudo_downdate(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.binary_full_tree_rss_pseudo_downdate(self, features, response, weight)

    def print_info(self) -> "void":
        r"""

        `print_info() const `  

        """
        return _regression.binary_full_tree_rss_print_info(self)

    def save_latex_representation(self, filename: "char const *") -> "void":
        r"""

        `save_latex_representation(const char *filename) const `  

        a visualization by generating a LaTeX document that can be compiled  

        Parameters
        ----------
        * `filename` :  
            Name of the file that will be used. Note that any existing file will be
            silently overwritten!  

        """
        return _regression.binary_full_tree_rss_save_latex_representation(self, filename)

# Register binary_full_tree_rss in _regression:
_regression.binary_full_tree_rss_swigregister(binary_full_tree_rss)

class forest_opts(object, metaclass=_SwigNonDynamicMeta):
    r"""


    Attributes
    ----------
    * `num_trees` : `index_t`  
        number of trees in the forest  

    * `num_data_points_per_tree` : `index_t`  
        number of datapoints used in each tree  

    * `do_bootstrapping` : `bool`  
        flag to toggle bootstrapping  

    * `compute_oob_error` : `bool`  
        flag to enable/disable computing the out-of-bag error  

    * `compute_law_of_total_variance` : `bool`  
        flag to enable/disable computation with the lotv  

    * `tree_opts` : `rfr::trees::tree_options< num_t, response_t, index_t >`  
        the options for each tree  

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr
    num_trees = property(_regression.forest_opts_num_trees_get, _regression.forest_opts_num_trees_set)
    num_data_points_per_tree = property(_regression.forest_opts_num_data_points_per_tree_get, _regression.forest_opts_num_data_points_per_tree_set)
    do_bootstrapping = property(_regression.forest_opts_do_bootstrapping_get, _regression.forest_opts_do_bootstrapping_set)
    compute_oob_error = property(_regression.forest_opts_compute_oob_error_get, _regression.forest_opts_compute_oob_error_set)
    compute_law_of_total_variance = property(_regression.forest_opts_compute_law_of_total_variance_get, _regression.forest_opts_compute_law_of_total_variance_set)
    tree_opts = property(_regression.forest_opts_tree_opts_get, _regression.forest_opts_tree_opts_set)

    def set_default_values(self) -> "void":
        r"""

        `set_default_values()`  

        (Re)set to default values for the forest.  

        """
        return _regression.forest_opts_set_default_values(self)

    def adjust_limits_to_data(self, data: "data_base") -> "void":
        r"""

        `adjust_limits_to_data(const rfr::data_containers::base< num_t, response_t,
            index_t > &data)`  

        adjusts all relevant variables to the data  

        """
        return _regression.forest_opts_adjust_limits_to_data(self, data)

    def __init__(self, *args):
        r"""

        `forest_options(rfr::trees::tree_options< num_t, response_t, index_t > &to,
            rfr::data_containers::base< num_t, response_t, index_t > &data)`  

        Constructor that adjusts to the data.  

        """
        _regression.forest_opts_swiginit(self, _regression.new_forest_opts(*args))

    def to_string(self) -> "std::string":
        r"""

        `to_string() const  -> std::string`  

        """
        return _regression.forest_opts_to_string(self)
    __swig_destroy__ = _regression.delete_forest_opts

# Register forest_opts in _regression:
_regression.forest_opts_swigregister(forest_opts)

class binary_rss_forest(object, metaclass=_SwigNonDynamicMeta):
    r"""


    Attributes
    ----------
    * `options` : `forest_options< num_t, response_t, index_t >`  

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr
    options = property(_regression.binary_rss_forest_options_get, _regression.binary_rss_forest_options_set)

    def __init__(self, *args):
        r"""

        `regression_forest(forest_options< num_t, response_t, index_t > opts)`  

        """
        _regression.binary_rss_forest_swiginit(self, _regression.new_binary_rss_forest(*args))
    __swig_destroy__ = _regression.delete_binary_rss_forest

    def fit(self, data: "data_base", rng: "default_random_engine") -> "void":
        r"""

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data,
            rng_type &rng)`  

        growing the random forest for a given data set  

        Parameters
        ----------
        * `data` :  
            a filled data container  
        * `rng` :  
            the random number generator to be used  

        """
        return _regression.binary_rss_forest_fit(self, data, rng)

    def predict(self, feature_vector: "num_vector") -> "double":
        r"""

        `predict(const std::vector< num_t > &feature_vector) const  -> response_t`  

        """
        return _regression.binary_rss_forest_predict(self, feature_vector)

    def predict_mean_var(self, feature_vector: "num_vector", weighted_data: "bool"=False) -> "std::pair< double,double >":
        r"""

        `predict_mean_var(const std::vector< num_t > &feature_vector, bool
            weighted_data=false) -> std::pair< num_t, num_t >`  

        """
        return _regression.binary_rss_forest_predict_mean_var(self, feature_vector, weighted_data)

    def covariance(self, f1: "num_vector", f2: "num_vector") -> "double":
        r"""

        `covariance(const std::vector< num_t > &f1, const std::vector< num_t > &f2) ->
            num_t`  

        """
        return _regression.binary_rss_forest_covariance(self, f1, f2)

    def kernel(self, f1: "num_vector", f2: "num_vector") -> "double":
        r"""

        `kernel(const std::vector< num_t > &f1, const std::vector< num_t > &f2) ->
            num_t`  

        """
        return _regression.binary_rss_forest_kernel(self, f1, f2)

    def all_leaf_values(self, feature_vector: "num_vector") -> "std::vector< std::vector< num_t,std::allocator< num_t > >,std::allocator< std::vector< num_t,std::allocator< num_t > > > >":
        r"""

        `all_leaf_values(const std::vector< num_t > &feature_vector) const  ->
            std::vector< std::vector< num_t > >`  

        """
        return _regression.binary_rss_forest_all_leaf_values(self, feature_vector)

    def pseudo_update(self, features: "num_vector", response: "double", weight: "double") -> "void":
        r"""

        `pseudo_update(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.binary_rss_forest_pseudo_update(self, features, response, weight)

    def pseudo_downdate(self, features: "num_vector", response: "double", weight: "double") -> "void":
        r"""

        `pseudo_downdate(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.binary_rss_forest_pseudo_downdate(self, features, response, weight)

    def out_of_bag_error(self) -> "double":
        r"""

        `out_of_bag_error() -> num_t`  

        """
        return _regression.binary_rss_forest_out_of_bag_error(self)

    def save_to_binary_file(self, filename: "std::string const") -> "void":
        r"""

        `save_to_binary_file(const std::string filename)`  

        """
        return _regression.binary_rss_forest_save_to_binary_file(self, filename)

    def load_from_binary_file(self, filename: "std::string const") -> "void":
        r"""

        `load_from_binary_file(const std::string filename)`  

        """
        return _regression.binary_rss_forest_load_from_binary_file(self, filename)

    def ascii_string_representation(self) -> "std::string":
        r"""

        `ascii_string_representation() -> std::string`  

        """
        return _regression.binary_rss_forest_ascii_string_representation(self)

    def load_from_ascii_string(self, str: "std::string const &") -> "void":
        r"""

        `load_from_ascii_string(std::string const &str)`  

        """
        return _regression.binary_rss_forest_load_from_ascii_string(self, str)

    def save_latex_representation(self, filename_template: "std::string const") -> "void":
        r"""

        `save_latex_representation(const std::string filename_template)`  

        """
        return _regression.binary_rss_forest_save_latex_representation(self, filename_template)

    def print_info(self) -> "void":
        r"""

        `print_info()`  

        """
        return _regression.binary_rss_forest_print_info(self)

    def num_trees(self) -> "unsigned int":
        r"""

        `num_trees() -> unsigned int`  

        """
        return _regression.binary_rss_forest_num_trees(self)

    def __getstate__(self):
    	d = {}
    	d['str_representation'] = self.ascii_string_representation()
    	return (d)

    def __setstate__(self, sState):
    	self.__init__()
    	self.load_from_ascii_string(sState['str_representation'])


# Register binary_rss_forest in _regression:
_regression.binary_rss_forest_swigregister(binary_rss_forest)

class qr_forest(binary_rss_forest):
    r"""


    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, *args):
        r"""

        `quantile_regression_forest(forest_options< num_t, response_t, index_t >
            forest_opts)`  

        """
        _regression.qr_forest_swiginit(self, _regression.new_qr_forest(*args))
    __swig_destroy__ = _regression.delete_qr_forest

    def predict_quantiles(self, feature_vector: "num_vector", quantiles: "num_vector") -> "std::vector< double,std::allocator< double > >":
        r"""

        `predict_quantiles(const std::vector< num_t > &feature_vector, std::vector<
            num_t > quantiles) const  -> std::vector< num_t >`  

        """
        return _regression.qr_forest_predict_quantiles(self, feature_vector, quantiles)

# Register qr_forest in _regression:
_regression.qr_forest_swigregister(qr_forest)

class fanova_forest_prototype(object, metaclass=_SwigNonDynamicMeta):
    r"""


    Attributes
    ----------
    * `options` : `forest_options< num_t, response_t, index_t >`  

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr
    options = property(_regression.fanova_forest_prototype_options_get, _regression.fanova_forest_prototype_options_set)

    def __init__(self, *args):
        r"""

        `regression_forest(forest_options< num_t, response_t, index_t > opts)`  

        """
        _regression.fanova_forest_prototype_swiginit(self, _regression.new_fanova_forest_prototype(*args))
    __swig_destroy__ = _regression.delete_fanova_forest_prototype

    def fit(self, data: "data_base", rng: "default_random_engine") -> "void":
        r"""

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data,
            rng_type &rng)`  

        growing the random forest for a given data set  

        Parameters
        ----------
        * `data` :  
            a filled data container  
        * `rng` :  
            the random number generator to be used  

        """
        return _regression.fanova_forest_prototype_fit(self, data, rng)

    def predict(self, feature_vector: "num_vector") -> "double":
        r"""

        `predict(const std::vector< num_t > &feature_vector) const  -> response_t`  

        """
        return _regression.fanova_forest_prototype_predict(self, feature_vector)

    def predict_mean_var(self, feature_vector: "num_vector", weighted_data: "bool"=False) -> "std::pair< double,double >":
        r"""

        `predict_mean_var(const std::vector< num_t > &feature_vector, bool
            weighted_data=false) -> std::pair< num_t, num_t >`  

        """
        return _regression.fanova_forest_prototype_predict_mean_var(self, feature_vector, weighted_data)

    def covariance(self, f1: "num_vector", f2: "num_vector") -> "double":
        r"""

        `covariance(const std::vector< num_t > &f1, const std::vector< num_t > &f2) ->
            num_t`  

        """
        return _regression.fanova_forest_prototype_covariance(self, f1, f2)

    def kernel(self, f1: "num_vector", f2: "num_vector") -> "double":
        r"""

        `kernel(const std::vector< num_t > &f1, const std::vector< num_t > &f2) ->
            num_t`  

        """
        return _regression.fanova_forest_prototype_kernel(self, f1, f2)

    def all_leaf_values(self, feature_vector: "num_vector") -> "std::vector< std::vector< num_t,std::allocator< num_t > >,std::allocator< std::vector< num_t,std::allocator< num_t > > > >":
        r"""

        `all_leaf_values(const std::vector< num_t > &feature_vector) const  ->
            std::vector< std::vector< num_t > >`  

        """
        return _regression.fanova_forest_prototype_all_leaf_values(self, feature_vector)

    def pseudo_update(self, features: "num_vector", response: "double", weight: "double") -> "void":
        r"""

        `pseudo_update(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.fanova_forest_prototype_pseudo_update(self, features, response, weight)

    def pseudo_downdate(self, features: "num_vector", response: "double", weight: "double") -> "void":
        r"""

        `pseudo_downdate(std::vector< num_t > features, response_t response, num_t
            weight)`  

        """
        return _regression.fanova_forest_prototype_pseudo_downdate(self, features, response, weight)

    def out_of_bag_error(self) -> "double":
        r"""

        `out_of_bag_error() -> num_t`  

        """
        return _regression.fanova_forest_prototype_out_of_bag_error(self)

    def save_to_binary_file(self, filename: "std::string const") -> "void":
        r"""

        `save_to_binary_file(const std::string filename)`  

        """
        return _regression.fanova_forest_prototype_save_to_binary_file(self, filename)

    def load_from_binary_file(self, filename: "std::string const") -> "void":
        r"""

        `load_from_binary_file(const std::string filename)`  

        """
        return _regression.fanova_forest_prototype_load_from_binary_file(self, filename)

    def ascii_string_representation(self) -> "std::string":
        r"""

        `ascii_string_representation() -> std::string`  

        """
        return _regression.fanova_forest_prototype_ascii_string_representation(self)

    def load_from_ascii_string(self, str: "std::string const &") -> "void":
        r"""

        `load_from_ascii_string(std::string const &str)`  

        """
        return _regression.fanova_forest_prototype_load_from_ascii_string(self, str)

    def save_latex_representation(self, filename_template: "std::string const") -> "void":
        r"""

        `save_latex_representation(const std::string filename_template)`  

        """
        return _regression.fanova_forest_prototype_save_latex_representation(self, filename_template)

    def print_info(self) -> "void":
        r"""

        `print_info()`  

        """
        return _regression.fanova_forest_prototype_print_info(self)

    def num_trees(self) -> "unsigned int":
        r"""

        `num_trees() -> unsigned int`  

        """
        return _regression.fanova_forest_prototype_num_trees(self)

# Register fanova_forest_prototype in _regression:
_regression.fanova_forest_prototype_swigregister(fanova_forest_prototype)

class fanova_forest(fanova_forest_prototype):
    r"""


    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def __init__(self, *args):
        r"""

        `fANOVA_forest(forest_options< num_t, response_t, index_t > forest_opts)`  

        """
        _regression.fanova_forest_swiginit(self, _regression.new_fanova_forest(*args))
    __swig_destroy__ = _regression.delete_fanova_forest

    def fit(self, data: "data_base", rng: "default_random_engine") -> "void":
        r"""

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data, rng_t
            &rng)`  

        growing the random forest for a given data set  

        Parameters
        ----------
        * `data` :  
            a filled data container  
        * `rng` :  
            the random number generator to be used  

        """
        return _regression.fanova_forest_fit(self, data, rng)

    def set_cutoffs(self, lower: "double", upper: "double") -> "void":
        r"""

        `set_cutoffs(num_t lower, num_t upper)`  

        """
        return _regression.fanova_forest_set_cutoffs(self, lower, upper)

    def get_cutoffs(self) -> "std::pair< double,double >":
        r"""

        `get_cutoffs() -> std::pair< num_t, num_t >`  

        """
        return _regression.fanova_forest_get_cutoffs(self)

    def precompute_marginals(self) -> "void":
        r"""

        `precompute_marginals()`  

        """
        return _regression.fanova_forest_precompute_marginals(self)

    def marginal_mean_prediction(self, feature_vector: "num_vector") -> "double":
        r"""

        `marginal_mean_prediction(const std::vector< num_t > &feature_vector) -> num_t`  

        """
        return _regression.fanova_forest_marginal_mean_prediction(self, feature_vector)

    def marginal_mean_variance_prediction(self, feature_vector: "num_vector") -> "std::pair< double,double >":
        r"""

        `marginal_mean_variance_prediction(const std::vector< num_t > &feature_vector)
            -> std::pair< num_t, num_t >`  

        """
        return _regression.fanova_forest_marginal_mean_variance_prediction(self, feature_vector)

    def marginal_prediction_stat_of_tree(self, tree_index: "unsigned int", feature_vector: "num_vector") -> "rfr::util::weighted_running_statistics< double >":
        r"""

        `marginal_prediction_stat_of_tree(index_t tree_index, const std::vector< num_t >
            &feature_vector) -> rfr::util::weighted_running_statistics< num_t >`  

        """
        return _regression.fanova_forest_marginal_prediction_stat_of_tree(self, tree_index, feature_vector)

    def get_trees_total_variances(self) -> "std::vector< double,std::allocator< double > >":
        r"""

        `get_trees_total_variances() -> std::vector< num_t >`  

        """
        return _regression.fanova_forest_get_trees_total_variances(self)

    def all_split_values(self) -> "std::vector< std::vector< std::vector< num_t,std::allocator< num_t > >,std::allocator< std::vector< num_t,std::allocator< num_t > > > >,std::allocator< std::vector< std::vector< num_t,std::allocator< num_t > >,std::allocator< std::vector< num_t,std::allocator< num_t > > > > > >":
        r"""

        `all_split_values() -> std::vector< std::vector< std::vector< num_t > > >`  

        """
        return _regression.fanova_forest_all_split_values(self)

# Register fanova_forest in _regression:
_regression.fanova_forest_swigregister(fanova_forest)

class binary_mondrian_forest(object, metaclass=_SwigNonDynamicMeta):
    r"""


    Attributes
    ----------
    * `options` : `forest_options< num_t, response_t, index_t >`  

    * `internal_index` : `index_t`  

    * `name` : `std::string`  

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __setattr__ = _swig_setattr_nondynamic_instance_variable(object.__setattr__)
    __repr__ = _swig_repr

    def get_trees(self) -> "std::vector< rfr::trees::k_ary_mondrian_tree< 2,rfr::nodes::k_ary_mondrian_node_full< 2,double,double,unsigned int,std::default_random_engine >,double,double,unsigned int,std::default_random_engine >,std::allocator< rfr::trees::k_ary_mondrian_tree< 2,rfr::nodes::k_ary_mondrian_node_full< 2,double,double,unsigned int,std::default_random_engine >,double,double,unsigned int,std::default_random_engine > > >":
        r"""

        `get_trees() const  -> std::vector< tree_t >`  

        """
        return _regression.binary_mondrian_forest_get_trees(self)
    options = property(_regression.binary_mondrian_forest_options_get, _regression.binary_mondrian_forest_options_set)
    internal_index = property(_regression.binary_mondrian_forest_internal_index_get, _regression.binary_mondrian_forest_internal_index_set)
    name = property(_regression.binary_mondrian_forest_name_get, _regression.binary_mondrian_forest_name_set)

    def __init__(self, *args):
        r"""

        `mondrian_forest(forest_options< num_t, response_t, index_t > opts)`  

        """
        _regression.binary_mondrian_forest_swiginit(self, _regression.new_binary_mondrian_forest(*args))
    __swig_destroy__ = _regression.delete_binary_mondrian_forest

    def fit(self, data: "data_base", rng: "default_random_engine") -> "void":
        r"""

        `fit(const rfr::data_containers::base< num_t, response_t, index_t > &data, rng_t
            &rng)`  

        growing the random forest for a given data set  

        Parameters
        ----------
        * `data` :  
            a filled data container  
        * `rng` :  
            the random number generator to be used  

        """
        return _regression.binary_mondrian_forest_fit(self, data, rng)

    def predict_mean_var(self, feature_vector: "num_vector") -> "std::pair< double,double >":
        r"""

        `predict_mean_var(const std::vector< num_t > &feature_vector) -> std::pair<
            num_t, num_t >`  

        """
        return _regression.binary_mondrian_forest_predict_mean_var(self, feature_vector)

    def predict(self, feature_vector: "num_vector") -> "double":
        r"""

        `predict(const std::vector< num_t > &feature_vector) const  -> response_t`  

        """
        return _regression.binary_mondrian_forest_predict(self, feature_vector)

    def predict_median(self, feature_vector: "num_vector") -> "double":
        r"""

        `predict_median(const std::vector< num_t > &feature_vector) -> response_t`  

        """
        return _regression.binary_mondrian_forest_predict_median(self, feature_vector)

    def partial_fit(self, data: "data_base", rng: "default_random_engine", point: "unsigned int") -> "void":
        r"""

        `partial_fit(const rfr::data_containers::base< num_t, response_t, index_t >
            &data, rng_t &rng, index_t point)`  

        """
        return _regression.binary_mondrian_forest_partial_fit(self, data, rng, point)

    def out_of_bag_error(self) -> "double":
        r"""

        `out_of_bag_error() -> num_t`  

        """
        return _regression.binary_mondrian_forest_out_of_bag_error(self)

    def save_to_binary_file(self, filename: "std::string const") -> "void":
        r"""

        `save_to_binary_file(const std::string filename)`  

        """
        return _regression.binary_mondrian_forest_save_to_binary_file(self, filename)

    def load_from_binary_file(self, filename: "std::string const") -> "void":
        r"""

        `load_from_binary_file(const std::string filename)`  

        """
        return _regression.binary_mondrian_forest_load_from_binary_file(self, filename)

    def ascii_string_representation(self) -> "std::string":
        r"""

        `ascii_string_representation() -> std::string`  

        """
        return _regression.binary_mondrian_forest_ascii_string_representation(self)

    def load_from_ascii_string(self, str: "std::string const &") -> "void":
        r"""

        `load_from_ascii_string(std::string const &str)`  

        """
        return _regression.binary_mondrian_forest_load_from_ascii_string(self, str)

    def save_latex_representation(self, filename_template: "std::string const") -> "void":
        r"""

        `save_latex_representation(const std::string filename_template)`  

        """
        return _regression.binary_mondrian_forest_save_latex_representation(self, filename_template)

    def print_info(self) -> "void":
        r"""

        `print_info()`  

        """
        return _regression.binary_mondrian_forest_print_info(self)

    def num_trees(self) -> "unsigned int":
        r"""

        `num_trees() -> unsigned int`  

        """
        return _regression.binary_mondrian_forest_num_trees(self)

# Register binary_mondrian_forest in _regression:
_regression.binary_mondrian_forest_swigregister(binary_mondrian_forest)



